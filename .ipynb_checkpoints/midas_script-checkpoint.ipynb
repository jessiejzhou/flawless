{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78386f61-ea63-41a5-80c1-ad1378f9d93b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0709a4b-52cc-4625-8102-c9d9cb3dc46e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/jessie/.cache/torch/hub/intel-isl_MiDaS_master\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'midas.dpt_depth'; 'midas' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDPT_Hybrid\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m midas \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mhub\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintel-isl/MiDaS\u001b[39m\u001b[38;5;124m\"\u001b[39m, model_type)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/hub.py:566\u001b[0m, in \u001b[0;36mload\u001b[0;34m(repo_or_dir, model, source, trust_repo, force_reload, verbose, skip_validation, *args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgithub\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    563\u001b[0m     repo_or_dir \u001b[38;5;241m=\u001b[39m _get_cache_or_reload(repo_or_dir, force_reload, trust_repo, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    564\u001b[0m                                        verbose\u001b[38;5;241m=\u001b[39mverbose, skip_validation\u001b[38;5;241m=\u001b[39mskip_validation)\n\u001b[0;32m--> 566\u001b[0m model \u001b[38;5;241m=\u001b[39m _load_local(repo_or_dir, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/hub.py:592\u001b[0m, in \u001b[0;36m_load_local\u001b[0;34m(hubconf_dir, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _add_to_sys_path(hubconf_dir):\n\u001b[1;32m    591\u001b[0m     hubconf_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(hubconf_dir, MODULE_HUBCONF)\n\u001b[0;32m--> 592\u001b[0m     hub_module \u001b[38;5;241m=\u001b[39m _import_module(MODULE_HUBCONF, hubconf_path)\n\u001b[1;32m    594\u001b[0m     entry \u001b[38;5;241m=\u001b[39m _load_entry_from_hubconf(hub_module, model)\n\u001b[1;32m    595\u001b[0m     model \u001b[38;5;241m=\u001b[39m entry(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/hub.py:106\u001b[0m, in \u001b[0;36m_import_module\u001b[0;34m(name, path)\u001b[0m\n\u001b[1;32m    104\u001b[0m module \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mmodule_from_spec(spec)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(spec\u001b[38;5;241m.\u001b[39mloader, Loader)\n\u001b[0;32m--> 106\u001b[0m spec\u001b[38;5;241m.\u001b[39mloader\u001b[38;5;241m.\u001b[39mexec_module(module)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/.cache/torch/hub/intel-isl_MiDaS_master/hubconf.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m dependencies \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmidas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdpt_depth\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DPTDepthModel\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmidas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmidas_net\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MidasNet\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmidas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmidas_net_custom\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MidasNet_small\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'midas.dpt_depth'; 'midas' is not a package"
     ]
    }
   ],
   "source": [
    "model_type = \"DPT_Hybrid\"\n",
    "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e68855e-48f4-431f-ab71-d1258a258834",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/jessie/.cache/torch/hub/intel-isl_MiDaS_master\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "midas.to(device)\n",
    "midas.eval()\n",
    "\n",
    "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
    "\n",
    "if model_type == \"DPT_Large\" or model_type == \"DPT_Hybrid\":\n",
    "    transform = midas_transforms.dpt_transform\n",
    "else:\n",
    "    transform = midas_transforms.small_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83450f36-3ed0-419f-8a4d-2a9483f43934",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Problem: the clips are too big. split them into scenes maybe\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m cap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDesktop/UCLA/datares/downloaded_celebvhq/raw/_0tf2n3rlJU.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "# Problem: the clips are too big. split them into scenes maybe\n",
    "\n",
    "cap = cv2.VideoCapture('Desktop/UCLA/datares/downloaded_celebvhq/raw/_0tf2n3rlJU.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4aa785-6906-4523-85a8-9c657b784814",
   "metadata": {},
   "outputs": [],
   "source": [
    "while cap.isOpened():\n",
    "\n",
    "    success, img = cap.read()\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Apply input transforms\n",
    "    input_batch = transform(img).to(device)\n",
    "\n",
    "    # Prediction and resize to original resolution\n",
    "    with torch.no_grad():\n",
    "        prediction = midas(input_batch)\n",
    "\n",
    "        prediction = torch.nn.functional.interpolate(\n",
    "            prediction.unsqueeze(1),\n",
    "            size=img.shape[:2],\n",
    "            mode=\"bicubic\",\n",
    "            align_corners=False,\n",
    "        ).squeeze()\n",
    "\n",
    "    depth_map = prediction.cpu().numpy()\n",
    "\n",
    "    depth_map = cv2.normalize(depth_map, None, 0, 1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_64F)\n",
    "\n",
    "\n",
    "    end = time.time()\n",
    "    totalTime = end - start\n",
    "\n",
    "    fps = 1 / totalTime\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    depth_map = (depth_map*255).astype(np.uint8)\n",
    "    depth_map = cv2.applyColorMap(depth_map , cv2.COLORMAP_MAGMA)\n",
    "\n",
    "    # print('depth_map.shape = ',depth_map.shape)\n",
    "    dim = (192*3, 108*4)\n",
    "    img = cv2.resize(img, dim, interpolation=cv2.INTER_AREA)\n",
    "    depth_map = cv2.resize(depth_map, dim, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # cv2.putText(img, f'FPS: {int(fps)}', (20,70), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0,255,0), 2)\n",
    "    cv2.imshow('Image', img)\n",
    "    cv2.imshow('Depth Map', depth_map)\n",
    "\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
